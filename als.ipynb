{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load table into pandas df\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "ratings_df = pd.read_csv('sample_data/ratings.csv')\n",
    "\n",
    "print(ratings_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"MovieRecommendationALS\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, temp_df = train_test_split(ratings_df, test_size=0.3, random_state=42) \n",
    "dev_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42) \n",
    "\n",
    "train_spark_df = spark.createDataFrame(train_df)\n",
    "dev_spark_df = spark.createDataFrame(dev_df)\n",
    "test_spark_df = spark.createDataFrame(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_ALS(train_data, validation_data, maxIter, rank):\n",
    "    # get ALS model\n",
    "    als = ALS(\n",
    "        maxIter=maxIter,\n",
    "        regParam=0,\n",
    "        rank=rank,\n",
    "        userCol=\"userId\",\n",
    "        itemCol=\"movieId\",\n",
    "        ratingCol=\"rating\",\n",
    "        coldStartStrategy=\"drop\")\n",
    "    # train ALS model\n",
    "    model = als.fit(train_data)\n",
    "    # evaluate the model by computing the RMSE on the validation data\n",
    "    predictions = model.transform(validation_data)\n",
    "    evaluator = RegressionEvaluator(metricName=\"mae\",\n",
    "                                    labelCol=\"rating\",\n",
    "                                    predictionCol=\"prediction\")\n",
    "    mae = evaluator.evaluate(predictions)\n",
    "    print(f\"{rank} latent factors, max iter = {maxIter}: validation MAE = {mae}\")\n",
    "\n",
    "# def tune_ALS(train_data, validation_data, maxIter, regParam, rank):\n",
    "#     # get ALS model\n",
    "#     als = ALS(\n",
    "#         maxIter=maxIter,\n",
    "#         regParam=regParam,\n",
    "#         rank=rank,\n",
    "#         userCol=\"userId\",\n",
    "#         itemCol=\"movieId\",\n",
    "#         ratingCol=\"rating\",\n",
    "#         coldStartStrategy=\"drop\")\n",
    "#     # train ALS model\n",
    "#     model = als.fit(train_data)\n",
    "#     # evaluate the model by computing the RMSE on the validation data\n",
    "#     predictions = model.transform(validation_data)\n",
    "#     evaluator = RegressionEvaluator(metricName=\"mae\",\n",
    "#                                     labelCol=\"rating\",\n",
    "#                                     predictionCol=\"prediction\")\n",
    "#     mae = evaluator.evaluate(predictions)\n",
    "#     print(f\"{rank} latent factors, regularization = {regParam}, max iter = {maxIter}: validation MAE = {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in [10, 20, 50]:\n",
    "    for r in [10, 20, 50]:\n",
    "      tune_ALS(train_spark_df, dev_spark_df, iter, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 latent factors, regularization = 0.01, max iter = 10: validation MAE = 0.8809409648936434\n",
    "# 20 latent factors, regularization = 0.01, max iter = 10: validation MAE = 0.9865915344359836\n",
    "# 50 latent factors, regularization = 0.01, max iter = 10: validation MAE = 1.092827599524713\n",
    "# 10 latent factors, regularization = 0.05, max iter = 10: validation MAE = 0.7407131944113025\n",
    "# 20 latent factors, regularization = 0.05, max iter = 10: validation MAE = 0.7574510508867892\n",
    "# 50 latent factors, regularization = 0.05, max iter = 10: validation MAE = 0.753138706570574\n",
    "# 10 latent factors, regularization = 0.1, max iter = 10: validation MAE = 0.6912527214782043 <- Best\n",
    "# 20 latent factors, regularization = 0.1, max iter = 10: validation MAE = 0.6950250406099087\n",
    "# 50 latent factors, regularization = 0.1, max iter = 10: validation MAE = 0.6919204329948865 \n",
    "# 10 latent factors, regularization = 0.01, max iter = 20: validation MAE = 0.892745112963494\n",
    "# 20 latent factors, regularization = 0.01, max iter = 20: validation MAE = 0.9969077982169593\n",
    "# 50 latent factors, regularization = 0.01, max iter = 20: validation MAE = 1.0373869455851963\n",
    "# 10 latent factors, regularization = 0.05, max iter = 20: validation MAE = 0.734153067477066\n",
    "# 20 latent factors, regularization = 0.05, max iter = 20: validation MAE = 0.7456158548305457\n",
    "# 50 latent factors, regularization = 0.05, max iter = 20: validation MAE = 0.7354275553562601\n",
    "# 10 latent factors, regularization = 0.1, max iter = 20: validation MAE = 0.6899199263238752\n",
    "# 20 latent factors, regularization = 0.1, max iter = 20: validation MAE = 0.6942792276238924\n",
    "# 50 latent factors, regularization = 0.1, max iter = 20: validation MAE = 0.6921828139817162 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ALS(train_data, test_data):\n",
    "    # get ALS model\n",
    "    als = ALS(\n",
    "        maxIter=10,\n",
    "        regParam=0.1,\n",
    "        rank=10,\n",
    "        userCol=\"userId\",\n",
    "        itemCol=\"movieId\",\n",
    "        ratingCol=\"rating\",\n",
    "        coldStartStrategy=\"drop\")\n",
    "    # train ALS model\n",
    "    model = als.fit(train_data)\n",
    "    # evaluate the model by computing the RMSE on the validation data\n",
    "    predictions = model.transform(test_data)\n",
    "    evaluator_mae = RegressionEvaluator(metricName=\"mae\",\n",
    "                                    labelCol=\"rating\",\n",
    "                                    predictionCol=\"prediction\")\n",
    "    evaluator_mse = RegressionEvaluator(metricName=\"mse\",\n",
    "                                    labelCol=\"rating\",\n",
    "                                    predictionCol=\"prediction\")\n",
    "    mae = evaluator_mae.evaluate(predictions)\n",
    "    mse = evaluator_mse.evaluate(predictions)\n",
    "\n",
    "    print(f\"MAE = {mae}, MSE = {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ALS(train_spark_df, test_spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE = 0.6899739807562887\n",
    "# MSE = 0.8052170727133248"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ALS(train_data):\n",
    "    # get ALS model\n",
    "    als = ALS(\n",
    "        maxIter=10,\n",
    "        regParam=0.1,\n",
    "        rank=10,\n",
    "        userCol=\"userId\",\n",
    "        itemCol=\"movieId\",\n",
    "        ratingCol=\"rating\",\n",
    "        coldStartStrategy=\"drop\")\n",
    "    # train ALS model\n",
    "    model = als.fit(train_data)\n",
    "\n",
    "    # return model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "trained_model = train_ALS(train_spark_df)\n",
    "\n",
    "# Fetch user and item matrices, then convert to pandas df\n",
    "user_factors = trained_model.userFactors\n",
    "item_factors = trained_model.itemFactors\n",
    "user_factors_df = user_factors.toPandas()\n",
    "item_factors_df = item_factors.toPandas()\n",
    "\n",
    "# Convert to np arrays\n",
    "user_factors_matrix = np.array(user_factors_df['features'].tolist())\n",
    "item_factors_matrix = np.array(item_factors_df['features'].tolist())\n",
    "user_ids = user_factors_df['id'].tolist()\n",
    "item_ids = item_factors_df['id'].tolist()\n",
    "\n",
    "# Matmul to create user-item matrix\n",
    "user_item_matrix = np.dot(user_factors_matrix, item_factors_matrix.T)\n",
    "\n",
    "user_item_df = pd.DataFrame(user_item_matrix, index=user_ids, columns=item_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_top_10_movies_for_user(user_item_df, user_id):\n",
    "    # Check if the user ID exists in the DataFrame\n",
    "    if user_id not in user_item_df.index:\n",
    "        raise ValueError(f\"User ID {user_id} not found in the DataFrame\")\n",
    "    \n",
    "    # Get the user's predicted ratings\n",
    "    user_ratings = user_item_df.loc[user_id]\n",
    "    \n",
    "    # Sort the ratings in descending order\n",
    "    sorted_ratings = user_ratings.sort_values(ascending=False)\n",
    "    \n",
    "    # Get the top 10 movie IDs\n",
    "    top_10_movie_ids = sorted_ratings.head(10).index.tolist()\n",
    "    \n",
    "    return top_10_movie_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "user_id = 1  # Replace with the desired user ID\n",
    "top_10_movies = get_top_10_movies_for_user(user_item_df, user_id)\n",
    "print(f\"Top 10 movies for user {user_id}: {top_10_movies}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs326",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
